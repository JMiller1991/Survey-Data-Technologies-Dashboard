{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "fee3cd0da99af27f7f7a8d9c340e8e78f253ffc32a2251cadcb6968f21d952d5"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"400\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# **Data Wrangling Lab**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Estimated time needed: **45 to 60** minutes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this assignment you will be performing data wrangling.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this lab you will perform the following:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "-   Identify duplicate values in the dataset.\n\n-   Remove duplicate values from the dataset.\n\n-   Identify missing values in the dataset.\n\n-   Impute the missing values in the dataset.\n\n-   Normalize data in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Hands on Lab\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Import pandas module.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-1-7dd3504c366f>:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "Load the dataset into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read Data</h2>\n<p>\nWe utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The functions below will download the dataset into your browser:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "To obtain the dataset, utilize the download() function as defined above:  \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "await download(file_path, \"m1_survey_data.csv\")\nfile_name=\"m1_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "Utilize the Pandas method read_csv() to load the data into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(file_name)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "> Note: This version of the lab is working on JupyterLite, which requires the dataset to be downloaded to the interface.While working on the downloaded version of this notebook on their local machines(Jupyter Anaconda), the learners can simply **skip the steps above,** and simply use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "## Finding duplicates\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this section you will identify duplicate values in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " Find how many duplicate rows exist in the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Find duplicate rows\nduplicate_rows = df.duplicated()\n\n# Count the number of duplicate rows\nnum_duplicates = duplicate_rows.sum()\nprint(f\"Number of duplicate rows: {num_duplicates}\")\nduplicate_data = df[df.duplicated()]\nprint(duplicate_data)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of duplicate rows: 154\n      Respondent                                         MainBranch Hobbyist  \\\n1168        2339                     I am a developer by profession      Yes   \n1169        2342                     I am a developer by profession      Yes   \n1170        2343                     I am a developer by profession      Yes   \n1171        2344                     I am a developer by profession      Yes   \n1172        2347                     I am a developer by profession      Yes   \n...          ...                                                ...      ...   \n2297        4674  I am not primarily a developer, but I write co...      Yes   \n2298        4675                     I am a developer by profession      Yes   \n2299        4676                     I am a developer by profession      Yes   \n2300        4677                     I am a developer by profession      Yes   \n2301        4679                     I am a developer by profession      Yes   \n\n                                            OpenSourcer  \\\n1168                         Once a month or more often   \n1169                                              Never   \n1170  Less than once a month but more than once per ...   \n1171                                              Never   \n1172                                              Never   \n...                                                 ...   \n2297                            Less than once per year   \n2298                                              Never   \n2299                                              Never   \n2300                         Once a month or more often   \n2301  Less than once a month but more than once per ...   \n\n                                             OpenSource          Employment  \\\n1168  OSS is, on average, of HIGHER quality than pro...  Employed full-time   \n1169  The quality of OSS and closed source software ...  Employed full-time   \n1170  OSS is, on average, of LOWER quality than prop...  Employed full-time   \n1171  The quality of OSS and closed source software ...  Employed full-time   \n1172  OSS is, on average, of HIGHER quality than pro...  Employed full-time   \n...                                                 ...                 ...   \n2297  The quality of OSS and closed source software ...  Employed full-time   \n2298  OSS is, on average, of HIGHER quality than pro...  Employed full-time   \n2299  OSS is, on average, of HIGHER quality than pro...  Employed full-time   \n2300  OSS is, on average, of HIGHER quality than pro...  Employed full-time   \n2301  The quality of OSS and closed source software ...  Employed full-time   \n\n             Country Student  \\\n1168   United States      No   \n1169  United Kingdom      No   \n1170          Canada      No   \n1171   United States      No   \n1172  United Kingdom      No   \n...              ...     ...   \n2297      Bangladesh      No   \n2298   United States      No   \n2299         Finland      No   \n2300  United Kingdom      No   \n2301   United States      No   \n\n                                                EdLevel  \\\n1168  Some college/university study without earning ...   \n1169  Some college/university study without earning ...   \n1170        Master’s degree (MA, MS, M.Eng., MBA, etc.)   \n1171           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n1172        Master’s degree (MA, MS, M.Eng., MBA, etc.)   \n...                                                 ...   \n2297           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n2298           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n2299        Master’s degree (MA, MS, M.Eng., MBA, etc.)   \n2300           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n2301        Master’s degree (MA, MS, M.Eng., MBA, etc.)   \n\n                                         UndergradMajor  ...  \\\n1168  Computer science, computer engineering, or sof...  ...   \n1169  Information systems, information technology, o...  ...   \n1170  Computer science, computer engineering, or sof...  ...   \n1171  Computer science, computer engineering, or sof...  ...   \n1172  Computer science, computer engineering, or sof...  ...   \n...                                                 ...  ...   \n2297                                                NaN  ...   \n2298  Information systems, information technology, o...  ...   \n2299  Another engineering discipline (ex. civil, ele...  ...   \n2300  A natural science (ex. biology, chemistry, phy...  ...   \n2301  Computer science, computer engineering, or sof...  ...   \n\n                                 WelcomeChange  \\\n1168   Just as welcome now as I felt last year   \n1169  Somewhat more welcome now than last year   \n1170  Somewhat more welcome now than last year   \n1171   Just as welcome now as I felt last year   \n1172   Just as welcome now as I felt last year   \n...                                        ...   \n2297  Somewhat less welcome now than last year   \n2298   Just as welcome now as I felt last year   \n2299  Somewhat less welcome now than last year   \n2300   Just as welcome now as I felt last year   \n2301   Just as welcome now as I felt last year   \n\n                                           SONewContent   Age Gender Trans  \\\n1168                                                NaN  24.0    Man    No   \n1169  Tech meetups or events in your area;Courses on...  24.0    Man    No   \n1170  Tech articles written by other developers;Indu...  27.0    Man    No   \n1171  Tech articles written by other developers;Indu...  24.0    Man    No   \n1172                                                NaN   NaN  Woman    No   \n...                                                 ...   ...    ...   ...   \n2297  Tech articles written by other developers;Indu...  31.0    Man    No   \n2298                Tech meetups or events in your area  27.0    Man    No   \n2299                                                NaN  36.0    Man    No   \n2300                                                NaN  40.0    Man    No   \n2301                                                NaN  27.0    Man    No   \n\n                                            Sexuality  \\\n1168                          Straight / Heterosexual   \n1169                          Straight / Heterosexual   \n1170                          Straight / Heterosexual   \n1171                          Straight / Heterosexual   \n1172                          Straight / Heterosexual   \n...                                               ...   \n2297  Bisexual;Gay or Lesbian;Straight / Heterosexual   \n2298                          Straight / Heterosexual   \n2299                          Straight / Heterosexual   \n2300                          Straight / Heterosexual   \n2301                                              NaN   \n\n                                              Ethnicity Dependents  \\\n1168                       White or of European descent         No   \n1169                       White or of European descent         No   \n1170  Black or of African descent;White or of Europe...         No   \n1171                       White or of European descent         No   \n1172                                           Biracial         No   \n...                                                 ...        ...   \n2297  Black or of African descent;Hispanic or Latino...        Yes   \n2298                       White or of European descent         No   \n2299                       White or of European descent        Yes   \n2300                       White or of European descent        Yes   \n2301                       White or of European descent         No   \n\n               SurveyLength                  SurveyEase  \n1168  Appropriate in length                        Easy  \n1169               Too long                        Easy  \n1170  Appropriate in length  Neither easy nor difficult  \n1171  Appropriate in length                        Easy  \n1172               Too long                        Easy  \n...                     ...                         ...  \n2297               Too long  Neither easy nor difficult  \n2298  Appropriate in length                        Easy  \n2299               Too long                        Easy  \n2300  Appropriate in length                        Easy  \n2301  Appropriate in length                        Easy  \n\n[154 rows x 85 columns]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "## Removing duplicates\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Remove the duplicate rows from the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Remove duplicate rows in the original DataFrame\ndf.drop_duplicates(inplace=True)\n\n# Verify the number of rows in the modified DataFrame\nprint(f\"Number of rows after removing duplicates: {df.shape[0]}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of rows after removing duplicates: 11398\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "Verify if duplicates were actually dropped.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Number of rows before dropping duplicates\nrows_before = df.shape[0]\n\n# Remove duplicates and create a cleaned DataFrame\ndf_cleaned = df.drop_duplicates()\n\n# Number of rows after dropping duplicates\nrows_after = df_cleaned.shape[0]\n\n# Print verification details\nprint(f\"Number of rows before dropping duplicates: {rows_before}\")\nprint(f\"Number of rows after dropping duplicates: {rows_after}\")\n\n# Check if any duplicates remain\nremaining_duplicates = df_cleaned.duplicated().sum()\nprint(f\"Number of remaining duplicate rows: {remaining_duplicates}\")\n\n# Visually confirm the cleaned dataset\nprint(df_cleaned.head())\n\n# Step 1: Remove duplicate rows\ndf_cleaned = df.drop_duplicates()\n\n# Step 2: Count missing (blank) rows in 'EdLevel'\nmissing_edlevel = df_cleaned['EdLevel'].isnull().sum()\n\n# Print the result\nprint(f\"Number of blank rows in 'EdLevel' after removing duplicates: {missing_edlevel}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of rows before dropping duplicates: 11398\nNumber of rows after dropping duplicates: 11398\nNumber of remaining duplicate rows: 0\n   Respondent                      MainBranch Hobbyist  \\\n0           4  I am a developer by profession       No   \n1           9  I am a developer by profession      Yes   \n2          13  I am a developer by profession      Yes   \n3          16  I am a developer by profession      Yes   \n4          17  I am a developer by profession      Yes   \n\n                                         OpenSourcer  \\\n0                                              Never   \n1                         Once a month or more often   \n2  Less than once a month but more than once per ...   \n3                                              Never   \n4  Less than once a month but more than once per ...   \n\n                                          OpenSource          Employment  \\\n0  The quality of OSS and closed source software ...  Employed full-time   \n1  The quality of OSS and closed source software ...  Employed full-time   \n2  OSS is, on average, of HIGHER quality than pro...  Employed full-time   \n3  The quality of OSS and closed source software ...  Employed full-time   \n4  The quality of OSS and closed source software ...  Employed full-time   \n\n          Country Student                                            EdLevel  \\\n0   United States      No           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n1     New Zealand      No  Some college/university study without earning ...   \n2   United States      No        Master’s degree (MA, MS, M.Eng., MBA, etc.)   \n3  United Kingdom      No        Master’s degree (MA, MS, M.Eng., MBA, etc.)   \n4       Australia      No           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n\n                                      UndergradMajor  ...  \\\n0  Computer science, computer engineering, or sof...  ...   \n1  Computer science, computer engineering, or sof...  ...   \n2  Computer science, computer engineering, or sof...  ...   \n3                                                NaN  ...   \n4  Computer science, computer engineering, or sof...  ...   \n\n                              WelcomeChange  \\\n0   Just as welcome now as I felt last year   \n1   Just as welcome now as I felt last year   \n2  Somewhat more welcome now than last year   \n3   Just as welcome now as I felt last year   \n4   Just as welcome now as I felt last year   \n\n                                        SONewContent   Age Gender Trans  \\\n0  Tech articles written by other developers;Indu...  22.0    Man    No   \n1                                                NaN  23.0    Man    No   \n2  Tech articles written by other developers;Cour...  28.0    Man    No   \n3  Tech articles written by other developers;Indu...  26.0    Man    No   \n4  Tech articles written by other developers;Indu...  29.0    Man    No   \n\n                 Sexuality                              Ethnicity Dependents  \\\n0  Straight / Heterosexual           White or of European descent         No   \n1                 Bisexual           White or of European descent         No   \n2  Straight / Heterosexual           White or of European descent        Yes   \n3  Straight / Heterosexual           White or of European descent         No   \n4  Straight / Heterosexual  Hispanic or Latino/Latina;Multiracial         No   \n\n            SurveyLength                  SurveyEase  \n0  Appropriate in length                        Easy  \n1  Appropriate in length  Neither easy nor difficult  \n2  Appropriate in length                        Easy  \n3  Appropriate in length  Neither easy nor difficult  \n4  Appropriate in length                        Easy  \n\n[5 rows x 85 columns]\nNumber of blank rows in 'EdLevel' after removing duplicates: 112\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "## Finding Missing values\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find the missing values for all columns.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Step 1: Remove duplicate rows\ndf_cleaned = df.drop_duplicates()\n\n# Step 2: Count missing rows in the 'Country' column\nmissing_country = df_cleaned['Country'].isnull().sum()\n\n# Print the result\nprint(f\"Number of missing rows in 'Country' after removing duplicates: {missing_country}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of missing rows in 'Country' after removing duplicates: 0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "Find out how many rows are missing in the column 'WorkLoc'\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Count the number of missing rows in the 'WorkLoc' column\nmissing_workloc = df['WorkLoc'].isnull().sum()\n\n# Print the result\nprint(f\"Number of missing rows in 'WorkLoc': {missing_workloc}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of missing rows in 'WorkLoc': 32\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "## Imputing missing values\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find the  value counts for the column WorkLoc.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get the value counts for the 'WorkLoc' column\nworkloc_counts = df['WorkLoc'].value_counts()\n\n# Print the result\nprint(\"Value counts for 'WorkLoc':\")\nprint(workloc_counts)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Value counts for 'WorkLoc':\nWorkLoc\nOffice                                            6806\nHome                                              3589\nOther place, such as a coworking space or cafe     971\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "Identify the value that is most frequent (majority) in the WorkLoc column.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Calculate the median of the 'ConvertedComp' column\nmedian_value = df['ConvertedComp'].median()\n\n# Impute missing values with the median\ndf['ConvertedComp'].fillna(median_value, inplace=True)\n\n# Calculate the most frequent value (mode) in the 'WorkLoc' column\nmost_frequent_value = df['WorkLoc'].mode()[0]  # Get the most frequent value",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-18-3945d876243f>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['ConvertedComp'].fillna(median_value, inplace=True)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Replace missing values with the most frequent value\ndf['WorkLoc'].fillna(most_frequent_value, inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "After imputation there should ideally not be any empty rows in the WorkLoc column.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Verify if imputing was successful.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Verify the result\nprint(f\"Number of missing values in 'WorkLoc' after imputation: {df['WorkLoc'].isnull().sum()}\")\n# your code goes here\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of missing values in 'WorkLoc' after imputation: 0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": "## Normalizing data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "There are two columns in the dataset that talk about compensation.\n\nOne is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n\nThe other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\". \n\nThis makes it difficult to compare the total compensation of the developers.\n\nIn this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n\nOnce this column is ready, it makes comparison of salaries easy.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "List out the various categories in the column 'CompFreq'\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Calculate the median of the 'NormalizedAnnualCompensation' column\nmedian_normalized_comp = df['NormalizedAnnualCompensation'].median()\n\n# Print the result\nprint(f\"The median NormalizedAnnualCompensation is: {median_normalized_comp}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'KeyError'>",
          "evalue": "'NormalizedAnnualCompensation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'NormalizedAnnualCompensation'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the median of the 'NormalizedAnnualCompensation' column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m median_normalized_comp \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNormalizedAnnualCompensation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print the result\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe median NormalizedAnnualCompensation is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmedian_normalized_comp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'NormalizedAnnualCompensation'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Double click to see the **Hint**.\n\n<!--\n\nUse the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n\nIf the CompFreq is Yearly then use the exising value in CompTotal\nIf the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\nIf the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define a function to normalize annual compensation\ndef normalize_compensation(row):\n    if row['CompFreq'] == 'Yearly':\n        return row['CompTotal']\n    elif row['CompFreq'] == 'Monthly':\n        return row['CompTotal'] * 12\n    elif row['CompFreq'] == 'Weekly':\n        return row['CompTotal'] * 52\n    else:\n        return None  # Handle missing or unknown CompFreq\n\n# Apply the function to create 'NormalizedAnnualCompensation'\ndf['NormalizedAnnualCompensation'] = df.apply(normalize_compensation, axis=1)\n\n# Display the first few rows to verify the new column\nprint(df[['CompFreq', 'CompTotal', 'NormalizedAnnualCompensation']].head())\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "  CompFreq  CompTotal  NormalizedAnnualCompensation\n0   Yearly    61000.0                       61000.0\n1   Yearly   138000.0                      138000.0\n2   Yearly    90000.0                       90000.0\n3  Monthly    29000.0                      348000.0\n4   Yearly    90000.0                       90000.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ramesh Sannareddy\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Other Contributors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Rav Ahuja\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " ## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2024-09-24|1.1|Madhusudhan Moole|Updated lab|\n|2024-09-23|1.0|Raghul Ramesh|Created lab|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n| ----------------- | ------- | ----------------- | ---------------------------------- |\n| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |--!>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}